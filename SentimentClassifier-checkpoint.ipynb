{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "    \n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text=text\n",
    "        self.score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score==3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:#score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def get_text(self):\n",
    "        return[x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return[x.sentiment for x in self.reviews]\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x : x.sentiment==Sentiment.NEGATIVE,self.reviews))\n",
    "        positive = list(filter(lambda x : x.sentiment==Sentiment.POSITIVE,self.reviews))\n",
    "        positive_shrink = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrink\n",
    "        random.shuffle(self.reviews)\n",
    "        #print(negative[0].text)\n",
    "        #print(len(negative))\n",
    "        #print(len(positive))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My Reflections:The well developed characters, the slow steady build all work together to deliver a tidy little package where mystery and history entwine.I loved the idea of a story centering on the decision, Franklyn Roosevelt devised to help people destroyed by the depression of 1935. His idea was to send families to a remote area of Alaska to colonies and grow the Matanuska Valley. The really superb thing about this book is these two authors use real and fictional characters to develop their narrative.Dr Jeremiah Vaughan's life is destroyed by allegations of abuse. When he uses a ground-breaking IV sedation technique with an influential patient, and the patient dies, the authorities are out for blood. This causes his license to be stripped away. Because of this, his intended and her mother want nothing to do with the shame. A has-been doctor is not what a high society woman wants on her arm. Fleeing from the hurt and rejection, from not only his fiance but also his own parents Jeremiah jumps at the chance to work alongside his mentor in a remote Alaskan village, far away from danger and pain...or so he thought.Gwyn is struggling with fear, rejection, and trust as she tends to her beloved village as a nurse. Her father (who is also the town's only doctor) is ecstatic at the prospect of seeing his village grow with the new colonization. As they race to ready the settlement for the new families, Gwyn must come to a place where she is able to accept the change and uncertainties of her future.This book was so surprising with it's villainous character and the twists and turns that ensued. It certainly was not the predictable book I imagined it to be.If you love fiction, history, romance, suspense you will probably enjoy this one. There are a few slow spots where the author is developing you knowledge of the characters, but by no means does it continue through the book. I will be keeping my eyes open for the sequel to this one.&#34;Book has been provided courtesy of Baker Publishing Group and Graf-Martin Communications, Inc.Available at your favourite bookseller from Bethany House, a division of Baker Publishing Group&#34;.\""
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "file_name = r'.\\Books_small_10000.json'\n",
    "reviews=[]\n",
    "with open(file_name) as f:\n",
    "    \n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "reviews[30].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24064"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training , test =train_test_split(reviews, test_size = 0.33, random_state = 42 )\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n",
    "\n",
    "cont.evenly_distribute()\n",
    "\n",
    "len(cont.reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6700"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Review object at 0x172F2FD0>\n"
     ]
    }
   ],
   "source": [
    "print(training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x=train_container.get_text()\n",
    "train_y=train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x=test_container.get_text()\n",
    "test_y=test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to read the reviews before I download a book, I guess now I am going to have to read about the reviewers before before I read the review before I download the book....I think somebody said  &#34;worth the time&#34;....well apparently their time isn't worth much because in my humble opinion, this was definitely one of the biggest wastes of my time yet....thank goodness it was short. I went back to read the reviews just now, and I'm sitting here shaking my head.....what did I miss??? The only reason I didn't give it one star is I don't want to hate anything. I seldom download short stories, the reviews swayed me.....I won't let that happen again...I mean, one nugget of wisdom could have made it worthwhile....the cover was also a tease....I guess the cover was worth the second star.  Sorry\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "#This book is great !\n",
    "#This book was bad\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "#TfidfVectorization improves performance by reducing the value of the repeated words in the document\n",
    "train_x_vectors=vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "#vectorizer.fit(train_x)\n",
    "#train_x_vectors = vectorizer.transform(train_x)\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "#### Linear svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors,train_y)\n",
    "test_x[0]\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "q=train_x_vectors.todense()\n",
    "p=test_x_vectors.todense()\n",
    "clf_gau = GaussianNB()#Memory error, should work in 64 bit though\n",
    "clf_gau.fit(q,train_y)\n",
    "clf_gau.predict(p[0])\n",
    "#we need to pass a dense matrix than a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "clf_log.predict(test_x_vectors[0])\n",
    "#dont worry about the error that pops up, it is a future error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6370192307692307\n",
      "0.5480769230769231\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors,test_y))\n",
    "print(clf_dec.score(test_x_vectors,test_y))\n",
    "print(clf_gau.score(p,test_y))\n",
    "print(clf_log.score(test_x_vectors,test_y))\n",
    "#Throws a ValueError if the dataset is big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80582524 0.80952381]\n",
      "[0.63788969 0.63614458]\n",
      "[0.59574468 0.66666667]\n",
      "[0.80291971 0.80760095]\n"
     ]
    }
   ],
   "source": [
    "#F1 Scores for the classifiers\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(test_y,clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y,clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y,clf_gau.predict(p), average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y,clf_log.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE,Sentiment.NEGATIVE]))\n",
    "#Throws a ValueError if the dataset is big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.count(Sentiment.POSITIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set=['I thoroughly enjoyed this', '2 stars', 'not great', 'bad book do not buy', 'horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the accuracy of the data with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'C:\\Users\\admin\\Documents\\Vilashnee\\College\\Learning materials\\Machine Learning\\sentiment_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\admin\\Documents\\Vilashnee\\College\\Learning materials\\Machine Learning\\sentiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I so enjoyed the Silo series and had high hopes for the 2 books y mMr Howey' What a let down . Wil look for his books on the sale shelf next time!these were more Tween books than adult.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[0])\n",
    "\n",
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
